import streamlit as st
from openai import OpenAI
from streamlit_agraph import agraph, Node, Edge, Config
from dotenv import load_dotenv
import os
import requests
import json
from neo4j import GraphDatabase, RoutingControl
import datetime
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'graph_utils')))
from graph_utils import execute_neo4j_query, convert_neo4j_to_graph
def show_node_properties(props):
    """Display node properties with a stylized title when available."""
    title = props.get("title") or props.get("display_name") or props.get("name")
    link = props.get("link")
    rest = {k: v for k, v in props.items() if k not in {"title", "display_name", "name", "link"}}
    if title and link:
        st.markdown(
            f"<h5 style='margin-bottom:0'><a href='{link}' target='_blank'>{title}</a></h5>",
            unsafe_allow_html=True,
        )
    elif title:
        st.markdown(f"**{title}**")
    if rest:
        st.json(rest)
def call_mcp_server(user_message):
    """Call MCP server to generate Cypher query"""
    try:
        # Replace with your actual MCP server endpoint
        mcp_endpoint = os.getenv("MCP_SERVER_ENDPOINT", "http://localhost:8000/generate-query")
        
        response = requests.post(
            mcp_endpoint,
            json={"message": user_message},
            headers={"Content-Type": "application/json"},
            timeout=10
        )
        
        if response.status_code == 200:
            data = response.json()
            return data.get("query", ""), data.get("parameters", {})
        else:
            st.error(f"MCP Server error: {response.status_code}")
            return "", {}
            
    except requests.exceptions.RequestException as e:
        st.error(f"Error calling MCP server: {str(e)}")
        return "", {}
def display_network_in_chat(nodes, edges):
    """Display network visualization with a node detail panel"""
    config = Config(
        width=1000,
        height=600,
        directed=True,
        physics=True,
        physics_props={
            "barnesHut": {
                "gravitationalConstant": -30000,  # ë…¸ë“œ ê°„ ì²™ë ¥ ì¦ê°€
                "centralGravity": 0.1,
                "springLength": 400,  # ì—£ì§€ ê¸¸ì´ ì¦ê°€
                "springConstant": 0.05,
                "damping": 0.05,
                "avoidOverlap": 1
            },
            "minVelocity": 0.75
        },
        staticGraphWithDragAndDrop=False,
        hierarchical=True,
        nodeHighlightBehavior=True,
        highlightColor="#F7A7A6",
        collapsible=False,
        node={
            "labelProperty": "label",
            "fontColor": "black",
            "fontSize": 14,
            "highlightFontSize": 16,
            "highlightStrokeColor": "#FF0000",
            "highlightStrokeWidth": 2
        },
        link={
            "labelProperty": "label",
            "renderLabel": True,
            "fontSize": 12,
            "highlightColor": "#FF0000",
            "linkDirectionalArrowLength": 20
        }
    )

    st.subheader("ğŸ“Š Network Visualization")
    col_graph, col_info = st.columns([2, 1])
    with col_graph:
        selected = agraph(nodes=nodes, edges=edges, config=config)
    # Build a lookup from node ID to stored properties so we can
    # show details even if the selected value is just the ID
    node_lookup = {str(n.id): getattr(n, "properties", {}) for n in nodes}
    with col_info:
        st.subheader("ğŸ›ˆ Selected Node")
        if selected:
            try:
                import dataclasses
                if dataclasses.is_dataclass(selected):
                    props = getattr(selected, "properties", None)
                    if props:
                        show_node_properties(props)
                    else:
                        data = dataclasses.asdict(selected)
                        show_node_properties(data)
                elif isinstance(selected, (str, int)):
                    props = node_lookup.get(str(selected))
                    if props:
                        show_node_properties(props)
                    else:
                        st.write(selected)
                elif isinstance(selected, dict):
                    props = selected.get("properties", selected)
                    show_node_properties(props)
                else:
                    st.write(selected)
            except Exception:
                st.write(selected)
def clean_messages_for_api(messages):
    """Clean messages to ensure they are JSON serializable for the API"""
    cleaned_messages = []
    
    for msg in messages:
        # Create a new message with only the essential fields
        cleaned_msg = {
            "role": msg["role"],
            "content": msg["content"]
        }
        cleaned_messages.append(cleaned_msg)
    
    return cleaned_messages
def stream_openai_response(client, messages):
    """Stream response from OpenAI API"""
    try:
        # Clean messages to ensure they are JSON serializable
        api_messages = clean_messages_for_api(messages)
        
        stream = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=api_messages,
            max_tokens=500,
            temperature=0.2,
            stream=True
        )
        
        response_placeholder = st.empty()
        full_response = ""
        
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                full_response += chunk.choices[0].delta.content
                response_placeholder.markdown(full_response + "â–Œ")
        
        response_placeholder.markdown(full_response)
        return full_response
        
    except Exception as e:
        st.error(f"Error streaming from OpenAI: {str(e)}")
        return "Sorry, I encountered an error while generating the response."
# Load environment variables
load_dotenv()
# Database and API configurations
NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_AUTH = (os.getenv("NEO4J_AUTH_USERNAME"), os.getenv("NEO4J_AUTH_PASSWORD"))
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key) if api_key else None
st.set_page_config(
    page_title="GraphRAG Chatbot with Stack Overflow",
    page_icon="https://cdn.sstatic.net/Sites/stackoverflow/company/img/logos/so/so-icon.png",
    layout="wide",
    initial_sidebar_state="collapsed"
)
# Sidebar with API status
st.sidebar.header("ğŸ”§ Configuration Status")
# Check API configurations in sidebar
if not api_key:
    st.sidebar.error("âš ï¸ OpenAI API key not found!")
else:
    st.sidebar.success("âœ… OpenAI API key loaded")
if not NEO4J_URI:
    st.sidebar.error("âš ï¸ Neo4j connection not configured!")
else:
    st.sidebar.success("âœ… Neo4j connection configured")
# Sidebar info
st.sidebar.markdown("---")
st.sidebar.markdown("""
**Environment Variables Required:**
- `OPENAI_API_KEY`: Your OpenAI API key
- `NEO4J_URI`: Neo4j database URI
- `NEO4J_AUTH_USERNAME`: Neo4j username
- `NEO4J_AUTH_PASSWORD`: Neo4j password
- `MCP_SERVER_ENDPOINT`: MCP server endpoint
""")
# Main content
st.image("https://stackoverflow.design/assets/img/logos/so/logo-stackoverflow.png", width=200)
st.title("ğŸ¤– GDBMS-Related Knowledge Retrieval Based on GraphRAG")
# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# Clear chat button - displayed as a floating button using simple CSS
clear_container = st.empty()
if clear_container.button("Clear Chat History"):
    st.session_state.messages = []
    st.rerun()

st.markdown(
    """
    <style>
        .stButton>button {
            position: fixed;
            bottom: 10px;
            right: 80px;
            z-index: 1000;
        }
    </style>
    """,
    unsafe_allow_html=True,
)

# Display all chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if message["role"] == "assistant" and "network_data" in message:
            # Display the text response first
            st.markdown(message["content"])
            
            # Then display the network visualization
            nodes, edges = message["network_data"]["nodes"], message["network_data"]["edges"]
            display_network_in_chat(nodes, edges)
            
            # Display query results details
            if "query_results" in message:
                with st.expander("ğŸ“‹ View Detailed Query Results", expanded=False):
                    results = message["query_results"]
                    for i, record in enumerate(results):
                        st.markdown(f"**Result {i+1}**")
                        for key, value in record.items():
                            if hasattr(value, 'labels') and hasattr(value, 'element_id'):
                                label = list(value.labels)[0] if value.labels else 'Node'
                                properties = dict(value.items()) if hasattr(value, 'items') else {}
                                st.markdown(f"**{key}** ({label})")
                                show_node_properties(properties)
                            elif hasattr(value, 'type') and hasattr(value, 'start_node'):
                                st.markdown(f"**{key}** (Relationship: {value.type})")
                            else:
                                st.markdown(f"**{key}**: {value}")
                        st.markdown("---")
        else:
            st.markdown(message["content"])
# Show info message only if no messages exist
if not st.session_state.messages:
    st.info("ğŸ’­ ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ì§€ì‹ì„ ë¬¼ì–´ë³´ì„¸ìš”!")
# Chat input
if prompt := st.chat_input("ì—¬ê¸°ì— ì§ˆë¬¸í•˜ì„¸ìš”"):
    # Add user message to chat history and display immediately
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Display the user message
    with st.chat_message("user"):
        st.markdown(prompt)

    # Process the message
    if api_key and NEO4J_URI:
        try:
            with st.chat_message("assistant"):
                # Step 1: Call MCP server to generate Cypher query
                with st.spinner("ğŸ” Generating database query..."):
                    cipher_query, query_params = call_mcp_server(prompt)
                    query_results = None
                    nodes = []
                    edges = []

                    if cipher_query:
                        # ì¿¼ë¦¬ë¬¸ì„ í™”ë©´ì— í‘œì‹œ
                        st.info(f"Generated query: `{cipher_query}`")

                        # Step 2: Execute query on Neo4j
                        with st.spinner("ğŸ“Š Querying database..."):
                            with GraphDatabase.driver(NEO4J_URI, auth=NEO4J_AUTH) as driver:
                                driver.verify_connectivity()
                                query_results = execute_neo4j_query(driver, cipher_query, query_params)

                                if query_results:
                                    st.success(f"Found {len(query_results)} results")
                                    # Step 3: Convert results to graph visualization
                                    nodes, edges = convert_neo4j_to_graph(query_results)
                                    st.write(f"ğŸ§ª nodes: {len(nodes)}, edges: {len(edges)}")
                                else:
                                    st.warning("No results found for the query")
                    else:
                        st.warning("Could not generate a valid database query")

                # --- [ìˆ˜ì •ë¨] ë…¸ë“œ ê°œìˆ˜ì— ë”°ë¼ AI ìš”ì•½ ì—¬ë¶€ ê²°ì • ---
                # Step 4: Generate response (AI summary or placeholder text)
                assistant_response = ""
                if len(nodes) >= 25:
                    # ë…¸ë“œê°€ 25ê°œ ì´ìƒì´ë©´ AI ìš”ì•½ì„ ê±´ë„ˆë›°ê³  ì•ˆë‚´ ë¬¸êµ¬ í‘œì‹œ
                    assistant_response = "ê²°ê³¼ê°€ ë„ˆë¬´ ë§ì•„(25ê°œ ì´ìƒ) ìš”ì•½ì„ ìƒëµí•˜ê³  ê·¸ë˜í”„ë§Œ í‘œì‹œí•©ë‹ˆë‹¤."
                    st.markdown(assistant_response)
                elif not query_results:
                    # ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ì„ ë•Œì˜ ê¸°ë³¸ ë‹µë³€
                    assistant_response = "í•´ë‹¹ ì§ˆë¬¸ì—ëŠ” ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" # <--- ì‚¬ìš©ì ìš”ì²­ ë¬¸êµ¬ë¡œ ìˆ˜ì •ë¨
                    st.markdown(assistant_response)
                else:
                    # ë…¸ë“œê°€ 25ê°œ ë¯¸ë§Œì´ë©´ ê¸°ì¡´ê³¼ ê°™ì´ AI ìš”ì•½ ìƒì„±
                    with st.spinner("ğŸ¤– Generating response..."):
                        system_content = "You are a helpful assistant that can discuss network graphs, database queries, data visualization, and any other topics. You have access to a Neo4j database and can help analyze graph data."
                        
                        if query_results:
                            results_summary = []
                            for i, record in enumerate(query_results[:5]):
                                record_summary = {}
                                for key, value in record.items():
                                    if hasattr(value, 'labels') and hasattr(value, 'element_id'):
                                        label = list(value.labels)[0] if value.labels else "Node"
                                        properties = dict(value.items()) if hasattr(value, 'items') else {}
                                        if 'creation_date' in properties and isinstance(properties['creation_date'], (int, float)):
                                            try:
                                                ts = properties['creation_date']
                                                properties['creation_date'] = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')
                                            except Exception: pass
                                        properties.pop('uuid', None)
                                        properties.pop('body_markdown', None)
                                        record_summary[key] = f"{label} with properties: {properties}"
                                    elif hasattr(value, 'type') and hasattr(value, 'start_node'):
                                        record_summary[key] = f"Relationship of type {value.type}"
                                    else: record_summary[key] = str(value)
                                results_summary.append(record_summary)
                            
                            if results_summary:
                                system_content += f"\n\nThe following query results were retrieved from the Neo4j database:\n{results_summary}\n\nBased ONLY on these results, answer the user's question factually and concisely. Do not add any interpretation, speculation, or analysis."

                        system_message = {"role": "system", "content": system_content}
                        messages_for_ai = [system_message] + st.session_state.messages
                        assistant_response = stream_openai_response(client, messages_for_ai)

                # --- [ìˆ˜ì •ë¨] ê³µí†µ ë¡œì§ìœ¼ë¡œ ë©”ì‹œì§€ ìƒì„± ë° ê·¸ë˜í”„/ê²°ê³¼ í‘œì‹œ ---
                # Create the final assistant message dictionary
                assistant_message = {"role": "assistant", "content": assistant_response}

                # Add network visualization and query results data to the message
                if nodes:
                    assistant_message["network_data"] = {"nodes": nodes, "edges": edges}
                    assistant_message["query_results"] = query_results
                    display_network_in_chat(nodes, edges)

                    if query_results:
                        # expander ì œëª©ì„ ê³ ìœ í•˜ê²Œ ë³€ê²½
                        with st.expander("ğŸ“‹ View Detailed Query Results (Current)", expanded=False):
                            for i, record in enumerate(query_results):
                                st.markdown(f"**Result {i+1}**")
                                for key, value in record.items():
                                    if hasattr(value, 'labels') and hasattr(value, 'element_id'):
                                        label = list(value.labels)[0] if value.labels else 'Node'
                                        properties = dict(value.items()) if hasattr(value, 'items') else {}
                                        st.markdown(f"**{key}** ({label})")
                                        show_node_properties(properties)
                                    elif hasattr(value, 'type') and hasattr(value, 'start_node'):
                                        st.markdown(f"**{key}** (Relationship: {value.type})")
                                    else:
                                        st.markdown(f"**{key}**: {value}")
                                st.markdown("---")
                
                # Add the complete assistant response to chat history
                st.session_state.messages.append(assistant_message)

        except Exception as e:
            error_msg = f"Error processing message: {str(e)}"
            with st.chat_message("assistant"):
                st.error(error_msg)
            st.session_state.messages.append({"role": "assistant", "content": error_msg})
    else:
        error_msg = "Cannot respond: Required API keys or database connection not configured"
        with st.chat_message("assistant"):
            st.error(error_msg)
        st.session_state.messages.append({"role": "assistant", "content": error_msg})