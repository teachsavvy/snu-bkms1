# nl2cypher_mcp.py

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
import openai
from dotenv import load_dotenv
import re

# 1. í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# 2. OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
from openai import OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 3. FastAPI ì•± ìƒì„± ë° CORS í—ˆìš©(port ë‹¤ë¥¼ ê²½ìš° ëŒ€ë¹„)
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì œí•œí•  ìˆ˜ë„ ìˆìŒ
    allow_methods=["*"],
    allow_headers=["*"],
)

# 4. ë°ì´í„° ì…ë ¥ í˜•ì‹ ì •ì˜
class QueryRequest(BaseModel):
    message: str

# 5. StackOverflow ìŠ¤í‚¤ë§ˆ í”„ë¡¬í”„íŠ¸
STACKOVERFLOW_SCHEMA = """
Graph Schema for StackOverflow Neo4j:

ğŸŸ¦ Nodes:
  - (q:Question)
      Properties:
        - uuid
        - title
        - creation_date
        - accepted_answer_id
        - link
        - view_count
        - answer_count
        - body_markdown

  - (u:User)
      Properties:
        - uuid
        - display_name

  - (a:Answer)
      Properties:
        - uuid
        - title
        - link
        - is_accepted
        - body_markdown
        - score

  - (t:Tag)
      Properties:
        - name
        - link

  - (c:Comment)
      Properties:
        - uuid
        - link
        - score

ğŸŸ¨ Relationships (You may assume or infer):
  - (u:User)-[:ASKED]->(q:Question)
  - (u:User)-[:PROVIDED]->(a:Answer)
  - (a:Answer)-[:ANSWERED]->(q:Question)
  - (q:Question)-[:TAGGED]->(t:Tag)
  - (u:User)-[:COMMENTED]->(c:Comment)
  - (c:Comment)-[:COMMENTED_ON]->(q:Question)
  - (c:Comment)-[:COMMENTED_ON]->(a:Answer)
"""


# 6. ìì—°ì–´ â†’ Cypher ë³€í™˜ í•¨ìˆ˜
def natural_language_to_cypher(nl_query: str) -> str:
    # [ìˆ˜ì •ë¨] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë”ìš± ëª…í™•í•˜ê³  ê°•ë ¥í•œ ê·œì¹™ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
    system_prompt = f"""
You are an expert Neo4j Cypher query translator, creating queries for a graph visualization tool.
Your primary goal is to write queries that return all the necessary data to draw a graph.

**Core Principles:**
- You MUST assign a variable to every relationship in a MATCH pattern (e.g., `[r:ASKED]`).
- The `RETURN` clause MUST include all variables for nodes and relationships defined in the `MATCH` clause.
- For aggregation queries (like counting), you MUST use a `WITH` clause to compute the aggregation before the final `RETURN`.

**See the following examples:**

---
**Example 1: Simple relationship query**
Natural language: "What are the latest questions from user 'A. L'?"
Correct Cypher: `MATCH (u:User {{display_name: 'A. L'}})-[r:ASKED]->(q:Question) RETURN u, r, q ORDER BY q.creation_date DESC LIMIT 3`

---
**Example 2: Aggregation query**
Natural language: "Which user asked the most questions?"
Correct Cypher: `MATCH (u:User)-[:ASKED]->(q:Question) WITH u, count(q) AS questionCount RETURN u.display_name, questionCount ORDER BY questionCount DESC LIMIT 1`

---
**Example 3: Multi-hop query**
Natural language: "Who answered questions tagged 'python'?"
Correct Cypher: `MATCH (u:User)-[r1:PROVIDED]->(a:Answer)-[r2:ANSWERED]->(q:Question)-[r3:TAGGED]->(t:Tag {{name: 'python'}}) RETURN u, r1, a, r2, q, r3, t`
---

Now, using the provided schema, translate the following question. Output ONLY the raw Cypher query.
"""

    user_prompt = f"""
Schema:
{STACKOVERFLOW_SCHEMA}

Natural language question:
"{nl_query}"

Cypher query:
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0,
        )

        query_text = response.choices[0].message.content.strip()
        query_text = re.sub(r'^```(?:cypher)?\n', '', query_text)
        query_text = re.sub(r'```$', '', query_text).strip()

        return query_text

    except openai.AuthenticationError:
        return "[ERROR] OpenAI API ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."
    except openai.RateLimitError:
        return "[ERROR] OpenAI API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
    except openai.APIConnectionError:
        return "[ERROR] OpenAI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”."
    except openai.APIError as e:
        return f"[ERROR] OpenAI APIê°€ ì—ëŸ¬ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤: {e}"
    except Exception as e:
        return f"[ERROR] ì¿¼ë¦¬ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# 7. MCP ì„œë²„ API ì—”ë“œí¬ì¸íŠ¸
@app.post("/generate-query")
def generate_query(request: QueryRequest):
    query = natural_language_to_cypher(request.message)
    return {"query": query, "parameters": {}}

# 8. ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    uvicorn.run("nl2cypher_mcp:app", host="0.0.0.0", port=8000, reload=True)